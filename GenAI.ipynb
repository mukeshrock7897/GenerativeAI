{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjE3juwC0PPbatMCD3cI4i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukeshrock7897/GenerativeAI/blob/main/GenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generative AI**\n",
        "\n",
        "# **Beginner Level**\n",
        "\n",
        "1. Introduction to Generative AI\n",
        "    * What is Generative AI?\n",
        "    * History and evolution\n",
        "    * Key concepts and terminology\n",
        "\n",
        "2. Types of Generative Models\n",
        "    * Overview of different generative models\n",
        "    * Comparison between generative and discriminative models\n",
        "\n",
        "3. Applications of Generative AI\n",
        "    * Image generation\n",
        "    * Text generation\n",
        "    * Music generation\n",
        "    * Other applications\n",
        "\n",
        "4. Ethical and Social Implications\n",
        "    * Bias and fairness\n",
        "    * Privacy concerns\n",
        "    * Ethical use of generative models\n"
      ],
      "metadata": {
        "id": "Fb4EFAVEc1hN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MtqMx2k_jbpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **1.Introduction to Generative AI**\n",
        "\n",
        "**What is Generative AI?**\n",
        "* Generative AI refers to the use of artificial intelligence to create new content, such as images, text, music, and more. It involves training models to generate data that is similar to a given dataset.\n",
        "\n",
        "**History and Evolution**\n",
        "* Overview of the development of generative AI, from early rule-based systems to modern deep learning models.\n",
        "\n",
        "**Key Concepts and Terminology**\n",
        "* Understanding essential terms such as generative models, training data, latent space, and sampling.\n",
        "\n",
        "**Types of Generative Models**\n",
        "\n",
        "* Overview of Different Generative Models\n",
        "\n",
        "   * Introduction to various generative models, including:\n",
        "     * Generative Adversarial Networks (GANs)\n",
        "     * Variational Autoencoders (VAEs)\n",
        "     * Autoregressive Models (e.g., GPT, PixelRNN)\n",
        "* Comparison Between Generative and Discriminative Models\n",
        "  * Explanation of the differences between generative models, which generate new data, and discriminative models, which classify data.\n",
        "\n",
        "**Applications of Generative AI**\n",
        "\n",
        "**Image Generation**\n",
        "* Use cases in art, design, and enhancing images. Examples include DeepArt and StyleGAN.\n",
        "\n",
        "**Text Generation**\n",
        "* Applications in content creation, summarization, and conversational agents. Examples include GPT-3 and ChatGPT.\n",
        "\n",
        "**Music Generation**\n",
        "* Creating music using models like OpenAI’s MuseNet or Jukedeck.\n",
        "\n",
        "**Other Applications**\n",
        "* Exploring generative AI in fields such as game design, drug discovery, and\n",
        "\n",
        "**video generation**\n",
        "* Ethical and Social Implications\n",
        "\n",
        "**Bias and Fairness**\n",
        "* Understanding how generative models can inherit and amplify biases present in training data.\n",
        "\n",
        "**Privacy Concerns**\n",
        "* Issues related to the generation of data that can mimic real individuals or sensitive content.\n",
        "\n",
        "**Ethical Use of Generative Models**\n",
        "* Discussion on the responsible use of generative AI, including potential misuse and guidelines for ethical deployment."
      ],
      "metadata": {
        "id": "UBSl4S8jdzaI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YE9BkOY2clrM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Intermediate Level**\n",
        "\n",
        "1. Generative Adversarial Networks (GANs)\n",
        "    * GAN architecture\n",
        "    * Training GANs\n",
        "    * Common GAN variants (e.g., DCGAN, CycleGAN)\n",
        "\n",
        "2. Variational Autoencoders (VAEs)\n",
        "    * VAE architecture\n",
        "    * Training VAEs\n",
        "    * Applications of VAEs\n",
        "\n",
        "3. Autoregressive Models\n",
        "    * Overview of autoregressive models\n",
        "    * PixelCNN and PixelRNN\n",
        "    * GPT (Generative Pre-trained Transformer)\n",
        "\n",
        "4. Flow-based Models\n",
        "    * Introduction to flow-based models\n",
        "    * Normalizing flows\n",
        "    * RealNVP and Glow\n",
        "\n",
        "5. Diffusion Models\n",
        "    * Basics of diffusion models\n",
        "    * Denoising diffusion probabilistic models\n"
      ],
      "metadata": {
        "id": "kYypPuBpjUqW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z-ZksDaBjXsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Generative Adversarial Networks (GANs)**\n",
        "\n",
        "**GAN Architecture**\n",
        "* Generative Adversarial Networks consist of two neural networks: the Generator and the Discriminator. The Generator creates fake data that mimics the real data, while the Discriminator tries to distinguish between real and fake data.\n",
        "\n",
        "    * **Generator:** Takes a random noise vector and generates data.\n",
        "    * **Discriminator:** Takes data (real or generated) and predicts whether it is real or fake."
      ],
      "metadata": {
        "id": "wQyktkgSjda5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(100, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 28*28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x).view(-1, 1, 28, 28)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(28*28, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x.view(-1, 28*28))\n"
      ],
      "metadata": {
        "id": "aD3iOpfrjqqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training GANs**\n",
        "* Training involves a two-step process where the Discriminator and Generator are trained alternately. The Discriminator learns to distinguish real from fake data, while the Generator learns to produce more realistic fake data to fool the Discriminator."
      ],
      "metadata": {
        "id": "u_Y061LfjxIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Initialize models\n",
        "G = Generator()\n",
        "D = Discriminator()\n",
        "\n",
        "# Loss and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(D.parameters(), lr=0.0002)\n",
        "optimizerG = optim.Adam(G.parameters(), lr=0.0002)\n",
        "\n",
        "for epoch in range(10000):\n",
        "    # Train Discriminator\n",
        "    real_data = torch.randn(batch_size, 28*28)\n",
        "    fake_data = G(torch.randn(batch_size, 100)).detach()\n",
        "    optimizerD.zero_grad()\n",
        "    lossD = criterion(D(real_data), torch.ones(batch_size, 1)) + \\\n",
        "            criterion(D(fake_data), torch.zeros(batch_size, 1))\n",
        "    lossD.backward()\n",
        "    optimizerD.step()\n",
        "\n",
        "    # Train Generator\n",
        "    fake_data = G(torch.randn(batch_size, 100))\n",
        "    optimizerG.zero_grad()\n",
        "    lossG = criterion(D(fake_data), torch.ones(batch_size, 1))\n",
        "    lossG.backward()\n",
        "    optimizerG.step()\n"
      ],
      "metadata": {
        "id": "NXcKimdDj2yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common GAN Variants**\n",
        "\n",
        "* **DCGAN (Deep Convolutional GAN):** Uses convolutional layers to improve the quality of generated images.\n",
        "* **CycleGAN:** Used for image-to-image translation without paired examples."
      ],
      "metadata": {
        "id": "cxpeO8jkj43l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Variational Autoencoders (VAEs)**\n",
        "\n",
        "**VAE Architecture**\n",
        "* VAEs consist of an encoder that maps input data to a latent space and a decoder that reconstructs the data from the latent space. Unlike traditional autoencoders, VAEs impose a probabilistic structure on the latent space."
      ],
      "metadata": {
        "id": "ESQUWFb-kCie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28*28, 400),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(400, 20)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(10, 400),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(400, 28*28),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        return h[:, :10], h[:, 10:]\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x.view(-1, 28*28))\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n"
      ],
      "metadata": {
        "id": "9N_2Lfu1j_5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training VAEs**\n",
        "* The training objective of VAEs is to minimize the reconstruction loss and the Kullback-Leibler divergence between the latent distribution and a prior distribution."
      ],
      "metadata": {
        "id": "AjztYCBEkVd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-1, 28*28), reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for data in dataloader:\n",
        "        x, _ = data\n",
        "        optimizer.zero_grad()\n",
        "        recon_x, mu, logvar = model(x)\n",
        "        loss = loss_function(recon_x, x, mu, logvar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ],
      "metadata": {
        "id": "0gjHAjVSkYiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applications of VAEs**\n",
        "* Image generation\n",
        "* Anomaly detection\n",
        "* Data augmentation\n"
      ],
      "metadata": {
        "id": "-dBA4Fg5kwg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Autoregressive Models**\n",
        "\n",
        "**Overview of Autoregressive Models**\n",
        "* Autoregressive models generate each output step-by-step, conditioned on previous steps.\n",
        "\n",
        "**Common examples include GPT and PixelCNN.**\n",
        "\n",
        "**PixelCNN and PixelRNN**\n",
        "* These models generate images pixel by pixel, where each pixel is conditioned on previously generated pixels."
      ],
      "metadata": {
        "id": "ZzKgcQmok3hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PixelCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PixelCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, padding=3)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=7, padding=3)\n",
        "        self.conv3 = nn.Conv2d(64, 1, kernel_size=7, padding=3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.conv1(x))\n",
        "        x = torch.sigmoid(self.conv2(x))\n",
        "        x = torch.sigmoid(self.conv3(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "85mAuvS0kzxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT (Generative Pre-trained Transformer)**\n",
        "* GPT models use the transformer architecture and are trained on large text corpora to generate human-like text."
      ],
      "metadata": {
        "id": "-cjDDIBxlMeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "input_text = \"Once upon a time\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "\n",
        "output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "1769icmrlRmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Flow-based Models**\n",
        "\n",
        "**Introduction to Flow-based Models**\n",
        "* Flow-based models use invertible neural networks to transform data into a latent space where it follows a simple distribution.\n",
        "\n",
        "**Normalizing Flows**\n",
        "* Normalizing flows are a series of invertible transformations applied to the data to match a target distribution."
      ],
      "metadata": {
        "id": "ONUugQ9elWc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NormalizingFlow(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NormalizingFlow, self).__init__()\n",
        "        self.layers = nn.ModuleList([AffineCoupling() for _ in range(4)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        log_det_jacobian = 0\n",
        "        for layer in self.layers:\n",
        "            x, ldj = layer(x)\n",
        "            log_det_jacobian += ldj\n",
        "        return x, log_det_jacobian\n",
        "\n",
        "    def inverse(self, z):\n",
        "        for layer in reversed(self.layers):\n",
        "            z = layer.inverse(z)\n",
        "        return z\n"
      ],
      "metadata": {
        "id": "24TlsAOMleLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RealNVP and Glow**\n",
        "* **RealNVP:** Introduced affine coupling layers for stable training.\n",
        "* **Glow:** Improved architecture with 1x1 convolutions and better performance.\n",
        "\n",
        "\n",
        "# **5. Diffusion Models**\n",
        "**Basics of Diffusion Models**\n",
        "* Diffusion models gradually add noise to the data during training and learn to reverse this process to generate data.\n",
        "\n",
        "**Denoising Diffusion Probabilistic Models**\n",
        "* These models use a series of denoising autoencoders to iteratively refine noisy data until it matches the target distribution."
      ],
      "metadata": {
        "id": "Vk9y8Obble5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DDPM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DDPM, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 1, kernel_size=3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        noise = torch.randn_like(x)\n",
        "        x_noisy = x + noise\n",
        "        encoded = self.encoder(x_noisy)\n",
        "        return self.decoder(encoded), noise"
      ],
      "metadata": {
        "id": "MtL3VOqHluqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mV6j2aFcl0ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advanced Level**\n",
        "\n",
        "1. Advanced Topics in Generative AI\n",
        "    * Advanced GAN architectures (e.g., StyleGAN, BigGAN)\n",
        "    * Advanced VAE techniques\n",
        "    * Advanced autoregressive models\n",
        "\n",
        "2. Practical Implementation and Tools\n",
        "    * Implementing generative models using frameworks (TensorFlow, PyTorch)\n",
        "    * Best practices for training generative models\n",
        "    * Debugging and improving generative models\n"
      ],
      "metadata": {
        "id": "I_aczEUkl3p8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OXJp6faSmW70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Advanced Topics in Generative AI**\n",
        "\n",
        "# **Advanced GAN Architectures**\n",
        "\n",
        "**StyleGAN**\n",
        "* StyleGAN introduces style transfer into GANs by injecting noise at different layers of the generator."
      ],
      "metadata": {
        "id": "93c9jOPBmYQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming pre-trained StyleGAN model is available\n",
        "from stylegan2_pytorch import ModelLoader\n",
        "\n",
        "model = ModelLoader(image_size=256, network_capacity=16)\n",
        "generated_image = model.generate_from_noise(1)\n",
        "generated_image.save('stylegan_image.png')\n"
      ],
      "metadata": {
        "id": "xt3_UPkrnHsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BigGAN**\n",
        "* BigGAN scales up GANs to generate high-quality images by using larger batch sizes and better architectural designs."
      ],
      "metadata": {
        "id": "mYwTOc3enIVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pseudo code for BigGAN\n",
        "from biggan import BigGAN, one_hot_from_names, truncated_noise_sample\n",
        "\n",
        "model = BigGAN.from_pretrained('biggan-deep-256')\n",
        "truncation = 0.4\n",
        "class_vector = one_hot_from_names(['dog', 'cat'], batch_size=1)\n",
        "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=1)\n",
        "generated_image = model(noise_vector, class_vector, truncation)\n"
      ],
      "metadata": {
        "id": "aOMHbbA_nNBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advanced VAE Techniques**\n",
        "\n",
        "**Beta-VAE**\n",
        "* Beta-VAE introduces a hyperparameter β to balance the trade-off between reconstruction and latent distribution regularization."
      ],
      "metadata": {
        "id": "LSJj_AsknOxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BetaVAE(nn.Module):\n",
        "    def __init__(self, beta=1):\n",
        "        super(BetaVAE, self).__init__()\n",
        "        self.beta = beta\n",
        "        # Define encoder and decoder here...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define forward pass here...\n",
        "        pass\n",
        "\n",
        "    def loss_function(self, recon_x, x, mu, logvar):\n",
        "        BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-1, 28*28), reduction='sum')\n",
        "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return BCE + self.beta * KLD\n"
      ],
      "metadata": {
        "id": "kiR3qjoZnoMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VQ-VAE (Vector Quantized VAE)**\n",
        "* VQ-VAE uses discrete latent variables for representation learning, which is useful for tasks like image generation and speech synthesis."
      ],
      "metadata": {
        "id": "ti1L-qxsnqgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VQVAE(nn.Module):\n",
        "    def __init__(self, K, D):\n",
        "        super(VQVAE, self).__init__()\n",
        "        self.embedding = nn.Embedding(K, D)\n",
        "        # Define encoder and decoder here...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define forward pass here...\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "Scjrpvg-nu12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advanced Autoregressive Models**\n",
        "\n",
        "**Transformer-XL**\n",
        "* Transformer-XL handles long-term dependencies better by segmenting the input sequence and using recurrence.\n",
        "\n"
      ],
      "metadata": {
        "id": "77-RtPxOnwmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TransfoXLModel, TransfoXLTokenizer\n",
        "\n",
        "tokenizer = TransfoXLTokenizer.from_pretrained('transfo-xl-wt103')\n",
        "model = TransfoXLModel.from_pretrained('transfo-xl-wt103')\n",
        "\n",
        "input_text = \"The quick brown fox\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "outputs = model(input_ids)\n"
      ],
      "metadata": {
        "id": "NOhKaCXKn2S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reformer**\n",
        "* Reformer uses locality-sensitive hashing and reversible layers to efficiently handle long sequences."
      ],
      "metadata": {
        "id": "loK3nZi7n4E2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from reformer_pytorch import ReformerLM\n",
        "\n",
        "model = ReformerLM(\n",
        "    num_tokens=20000,\n",
        "    dim=512,\n",
        "    depth=6,\n",
        "    max_seq_len=4096,\n",
        "    heads=8,\n",
        "    lsh_dropout=0.1,\n",
        "    causal=True\n",
        ")\n",
        "\n",
        "input_text = torch.randint(0, 20000, (1, 4096))\n",
        "output = model(input_text)\n"
      ],
      "metadata": {
        "id": "pLC-o-fCn8LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Practical Implementation and Tools**\n",
        "\n",
        "**Implementing Generative Models using Frameworks**\n",
        "\n",
        "**TensorFlow**\n",
        "* TensorFlow provides extensive support for building and training generative models."
      ],
      "metadata": {
        "id": "WXF7HwMYn9ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class GAN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(GAN, self).__init__()\n",
        "        self.generator = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(256, activation='relu'),\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(28*28, activation='tanh')\n",
        "        ])\n",
        "        self.discriminator = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(256, activation='relu'),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        generated_data = self.generator(inputs)\n",
        "        return self.discriminator(generated_data)\n"
      ],
      "metadata": {
        "id": "c3ZTT6iXoGN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PyTorch**\n",
        "* PyTorch is popular for its dynamic computational graph and ease of use."
      ],
      "metadata": {
        "id": "lawgqELmoIDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GAN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GAN, self).__init__()\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(100, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 28*28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.discriminator = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.discriminator(self.generator(x))\n"
      ],
      "metadata": {
        "id": "Te403ilPoMDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Practices for Training Generative Models**\n",
        "* **Hyperparameter tuning:** Systematically adjust hyperparameters for optimal performance.\n",
        "\n",
        "* **Regularization:** Use techniques like dropout and weight decay to prevent overfitting.\n",
        "* **Data augmentation:** Enhance training data with transformations to improve model robustness.\n",
        "\n",
        "\n",
        "**Debugging and Improving Generative Models**\n",
        "* **Visual inspection:** Regularly visualize generated samples to assess quality.\n",
        "* **Loss monitoring:** Track generator and discriminator losses to detect issues.\n",
        "* **Model architecture:** Experiment with different architectures and layer configurations."
      ],
      "metadata": {
        "id": "uIm7mnDooNwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.Advanced Topics**\n",
        "\n",
        "**Conditional Generative Models**\n",
        "* Conditional generative models generate data conditioned on certain inputs, such as class labels."
      ],
      "metadata": {
        "id": "mgiDnSD6oiw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConditionalGAN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ConditionalGAN, self).__init__()\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(100 + num_classes, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 28*28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.discriminator = nn.Sequential(\n",
        "            nn.Linear(28*28 + num_classes, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        x = torch.cat([x, labels], dim=1)\n",
        "        return self.discriminator(self.generator(x))\n"
      ],
      "metadata": {
        "id": "HzxflrPDofgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Meta-Learning and Few-Shot Learning**\n",
        "* Meta-learning techniques can adapt generative models to new tasks with limited data."
      ],
      "metadata": {
        "id": "h1Ro1V-UopRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmeta.datasets.helpers import miniimagenet\n",
        "from torchmeta.utils.data import BatchMetaDataLoader\n",
        "\n",
        "dataset = miniimagenet('data', ways=5, shots=1, test_shots=15, meta_train=True, download=True)\n",
        "dataloader = BatchMetaDataLoader(dataset, batch_size=16, num_workers=4)\n",
        "\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch['train']\n",
        "    # Model training code here...\n"
      ],
      "metadata": {
        "id": "haySOK8qot-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reinforcement Learning and Generative Models**\n",
        "* Combining reinforcement learning with generative models can lead to advanced applications like game playing and strategy optimization."
      ],
      "metadata": {
        "id": "hmMGZlnHowRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = gym.make('CartPole-v1')\n",
        "model = PPO('MlpPolicy', env, verbose=1)\n",
        "model.learn(total_timesteps=10000)"
      ],
      "metadata": {
        "id": "uGZn9QJvo1iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iNsQ3vxjp5F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **All Libraries and Tools in Generative AI**\n"
      ],
      "metadata": {
        "id": "OHL4jIRap62c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BuEbUa62qD88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Python Libraries and Frameworks:**\n",
        "1. TensorFlow\n",
        "2. Keras\n",
        "3. PyTorch\n",
        "4. Hugging Face Transformers\n",
        "5. OpenAI GPT-3/GPT-4\n",
        "6. Fastai\n",
        "7. GANLab\n",
        "8. GANMetrics\n",
        "9. StyleGAN2-ADA\n",
        "10. BigGAN-PyTorch\n",
        "11. VQ-VAE-2\n",
        "12. DiffWave\n",
        "13. MuseNet\n",
        "14. DeepArt\n",
        "15. Magenta\n",
        "16. Dreamer\n",
        "17. DeOldify\n",
        "18. RunwayML\n",
        "19. OpenCV\n",
        "20. Pydub\n",
        "21. Numpy\n",
        "22. Scipy\n",
        "23. Matplotlib\n",
        "24. Seaborn\n",
        "\n",
        "# **Specialized Tools and Libraries:**\n",
        "1. DALL-E\n",
        "2. CLIP\n",
        "3. DeepDream\n",
        "4. Jukebox\n",
        "5. Taming Transformers\n",
        "6. PPLM (Plug and Play Language Models)\n",
        "7. Reformer\n",
        "8. Longformer\n",
        "9. EleutherAI’s GPT-Neo\n",
        "10. GPT-J\n",
        "11. RealNVP\n",
        "12. Glow\n",
        "13. Neural Style Transfer (NST)\n",
        "\n",
        "# **Autoencoders and Variants:**\n",
        "1. Autoencoder (AE)\n",
        "2. Variational Autoencoder (VAE)\n",
        "3. Beta-VAE\n",
        "4. Conditional VAE (CVAE)\n",
        "5. Denoising Autoencoder (DAE)\n",
        "\n",
        "# **GANs and Variants:**\n",
        "1. Generative Adversarial Networks (GANs)\n",
        "2. Deep Convolutional GAN (DCGAN)\n",
        "3. CycleGAN\n",
        "4. StyleGAN\n",
        "5. BigGAN\n",
        "6. Conditional GAN (cGAN)\n",
        "7. Progressive GAN (PGGAN)\n",
        "8. Wasserstein GAN (WGAN)\n",
        "9. Least Squares GAN (LSGAN)\n",
        "\n",
        "# **Diffusion Models:**\n",
        "1. Denoising Diffusion Probabilistic Models (DDPM)\n",
        "2. Score-Based Generative Models\n",
        "\n",
        "# **Other Models:**\n",
        "1. PixelCNN\n",
        "2. PixelRNN\n",
        "3. GLOW\n",
        "4. RealNVP\n",
        "\n"
      ],
      "metadata": {
        "id": "h74UnWhcqEnn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pBnMEEoEqRls"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}